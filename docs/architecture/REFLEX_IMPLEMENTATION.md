# Fast Reflex Message Implementation

## Overview

This document describes the implementation of fast reflex messages, which allows the edge agent to send immediate responses (reflex) separately from follow-up messages (burst), creating a more natural and responsive conversation flow.

## Problem

Previously, all messages (reflex + burst) were generated by the backend and sent together as `reply_bubbles`. This meant the reflex message (which should feel immediate) arrived at the same time as the longer burst messages, making responses feel slower than they should.

## Solution

We've implemented a two-phase response system:

1. **Reflex Phase** - Immediate response sent within ~100ms
2. **Burst Phase** - Follow-up messages sent after a configurable delay (default: 2000ms)

## Edge Agent Changes (‚úÖ COMPLETED)

The edge agent now supports a new response structure from the backend:

### Updated `BackendMessageResponse` Interface

```typescript
export interface BackendMessageResponse {
  should_respond: boolean;

  // Legacy fields (still supported)
  reply_text?: string;
  reply_bubbles?: string[];

  // NEW: Fast reflex support
  reflex_message?: string;        // Immediate response (sent first)
  burst_messages?: string[];      // Follow-up messages (sent after delay)
  burst_delay_ms?: number;        // Delay before burst (default: 2000ms)
}
```

### Message Flow

When the edge agent receives a response from the backend:

1. **If `reflex_message` is present:**
   - ‚ö° Send reflex message **immediately**
   - ‚è≥ If `burst_messages` exist, schedule them with `burst_delay_ms` delay
   - Logs: `‚ö° Sending REFLEX message` and `‚è≥ Will send N burst messages after Xms`

2. **If `reply_bubbles` is present (legacy):**
   - üì§ Send all bubbles together using `sendMultiBubble()`
   - Maintains backward compatibility

3. **If `reply_text` is present (legacy):**
   - üì§ Send single message
   - Maintains backward compatibility

### Example Response Handling

```typescript
// Backend returns:
{
  "should_respond": true,
  "reflex_message": "ooh how was it?",
  "burst_messages": [
    "i've been wanting to check that place out!",
    "did you try their signature dish?"
  ],
  "burst_delay_ms": 2000
}

// Edge agent behavior:
// t=0ms:    ‚ö° Send "ooh how was it?"
// t=2000ms: üì§ Send "i've been wanting to check that place out!"
//           üì§ Send "did you try their signature dish?"
```

## Backend Changes Needed (üîß REQUIRED)

The backend needs to be updated to support this new response structure. Here's what needs to change:

### 1. Update `/edge/message` Endpoint Response

The endpoint should analyze the generated response and split it into reflex and burst components:

```python
# Example backend logic
def process_message(message):
    # Generate full response (as before)
    response_bubbles = generate_response(message)

    # NEW: Determine if first bubble is a reflex
    if should_use_reflex_fast_path(response_bubbles):
        return {
            "should_respond": True,
            "reflex_message": response_bubbles[0],  # First bubble as reflex
            "burst_messages": response_bubbles[1:],  # Rest as burst
            "burst_delay_ms": 2000  # Configurable delay
        }
    else:
        # Legacy path for non-reflex responses
        return {
            "should_respond": True,
            "reply_bubbles": response_bubbles
        }
```

### 2. Reflex Detection Logic

The backend should determine when to use the fast path based on:

- **Message characteristics**: Short, emotional, immediate reactions
- **Conversation context**: Reflex probability from persona model
- **Response structure**: First bubble is short and reactive

Example heuristics:
```python
def should_use_reflex_fast_path(bubbles):
    if len(bubbles) == 0:
        return False

    first_bubble = bubbles[0]

    # Check if first bubble looks like a reflex
    is_short = len(first_bubble) < 50  # Short messages
    has_exclamation = '!' in first_bubble or '?' in first_bubble
    is_emotional = contains_emotional_words(first_bubble)

    # Use reflex if it's a multi-bubble response with short first message
    return len(bubbles) > 1 and (is_short or has_exclamation or is_emotional)
```

### 3. Configurable Burst Delay

The backend can control the delay between reflex and burst:

```python
# Default delay
DEFAULT_BURST_DELAY_MS = 2000

# Dynamic delay based on burst content length
def calculate_burst_delay(burst_messages):
    # Longer burst = slightly longer delay to feel more natural
    total_chars = sum(len(msg) for msg in burst_messages)

    if total_chars < 100:
        return 1500  # Quick follow-up
    elif total_chars < 300:
        return 2000  # Normal delay
    else:
        return 3000  # Longer content, more "thinking" time
```

## Example Scenarios

### Scenario 1: Reflex + Burst
```
User: "Just had dinner at that new Italian place!"

Backend Response:
{
  "should_respond": true,
  "reflex_message": "ooh how was it?",  // Sent immediately
  "burst_messages": [
    "i've been wanting to check that place out!",
    "did you try their signature dish?"
  ],
  "burst_delay_ms": 2000  // Sent 2 seconds later
}
```

### Scenario 2: Reflex Only
```
User: "Feeling pretty stressed about this deadline"

Backend Response:
{
  "should_respond": true,
  "reflex_message": "ugh that sounds rough üíô",  // Sent immediately
  "burst_messages": [],  // No follow-up needed
  "burst_delay_ms": null
}
```

### Scenario 3: Legacy Multi-Bubble (No Reflex)
```
User: "Can you help me plan my trip to Japan?"

Backend Response:
{
  "should_respond": true,
  "reply_bubbles": [  // All sent together (planning/info response)
    "absolutely! what cities are you thinking?",
    "i can help with itinerary, food recs, all of it",
    "when are you planning to go?"
  ]
}
```

## Benefits

1. **Faster perceived response time**: User sees reflex within ~100ms
2. **More natural conversation**: Mimics human texting behavior (quick reaction, then elaboration)
3. **Backward compatible**: Legacy `reply_bubbles` still works
4. **Flexible timing**: Backend controls burst delay based on context

## Testing

To test the implementation:

1. Deploy edge agent with these changes
2. Update backend to return `reflex_message` + `burst_messages`
3. Send a test message and observe logs:
   ```
   ‚ö° Sending REFLEX message to thread_id
   ‚úÖ Reflex message sent immediately
   ‚è≥ Will send 2 burst messages after 2000ms
   üì§ Sending burst messages to thread_id
   ‚úÖ Burst messages sent successfully
   ```

## Files Changed

- `src/interfaces/IBackendClient.ts` - Added reflex/burst fields to interface
- `src/backend/RenderClient.ts` - Pass through reflex/burst fields from API
- `src/index.ts` - Implement fast reflex path with delayed burst sending

## Next Steps

**Backend team needs to:**
1. Update `/edge/message` endpoint to return new fields
2. Implement reflex detection logic
3. Test with edge agent
4. Deploy to production

Once deployed, users will experience noticeably faster and more natural responses!
